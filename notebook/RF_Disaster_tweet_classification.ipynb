{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Sentiment Analysis with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>char_counts</th>\n",
       "      <th>word_counts</th>\n",
       "      <th>avg_wordlength</th>\n",
       "      <th>stopwords_counts</th>\n",
       "      <th>hashtag_counts</th>\n",
       "      <th>mentions_counts</th>\n",
       "      <th>digits_counts</th>\n",
       "      <th>uppercase_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>our deeds are the reason of this earthquake ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>forest fire near la ronge sask canada</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>7</td>\n",
       "      <td>4.571429</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>all residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>22</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130 people receive wildfires evacuation orders...</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>8</td>\n",
       "      <td>7.125000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>just got sent this photo from ruby alaska as s...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>16</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  our deeds are the reason of this earthquake ma...   \n",
       "1   4     NaN      NaN              forest fire near la ronge sask canada   \n",
       "2   5     NaN      NaN  all residents asked to shelter in place are be...   \n",
       "3   6     NaN      NaN  130 people receive wildfires evacuation orders...   \n",
       "4   7     NaN      NaN  just got sent this photo from ruby alaska as s...   \n",
       "\n",
       "   target  char_counts  word_counts  avg_wordlength  stopwords_counts  \\\n",
       "0       1           57           13        4.384615                 6   \n",
       "1       1           32            7        4.571429                 0   \n",
       "2       1          112           22        5.090909                 9   \n",
       "3       1           57            8        7.125000                 1   \n",
       "4       1           72           16        4.500000                 6   \n",
       "\n",
       "   hashtag_counts  mentions_counts  digits_counts  uppercase_counts  \n",
       "0               1                0              0                 1  \n",
       "1               0                0              1                 0  \n",
       "2               0                0              1                 0  \n",
       "3               1                0              1                 0  \n",
       "4               2                0              0                 0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('clean_tweet.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6090,), (1523,))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import STOPWORDS\n",
    "stopwords = set(STOPWORDS)\n",
    "\n",
    "\n",
    "stopwords_list = list(stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score : 0.7760998030203545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       874\n",
      "           1       0.77      0.68      0.72       649\n",
      "\n",
      "    accuracy                           0.78      1523\n",
      "   macro avg       0.77      0.76      0.77      1523\n",
      "weighted avg       0.78      0.78      0.77      1523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Create a list of stopwords\n",
    "stopwords_list = list(stopwords)\n",
    "\n",
    "# Define the pipeline\n",
    "clf = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stopwords_list)),\n",
    "    ('clf', RandomForestClassifier(n_estimators=100, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "print(\"accuracy score :\",accuracy_score(y_test, predictions))\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf, open('model/RF_twitter_sentiment.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(['earthquake'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_disaster(sentences, model):\n",
    "    predictions = model.predict(sentences)\n",
    "    for sentence, pred in zip(sentences, predictions):\n",
    "        # Interpret the prediction\n",
    "        prediction_label = 'Disaster Tweet' if pred == 1 else 'Normal Tweet'\n",
    "        \n",
    "        # Print the sentence and its prediction\n",
    "        print(f\"Sentence: {sentence}\")\n",
    "        print(f\"Prediction: {prediction_label}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: An intense hurricane has made landfall, causing widespread flooding and destruction in coastal areas. Stay safe and evacuate if you can!\n",
      "Prediction: Disaster Tweet\n",
      "\n",
      "Sentence: Heard about #earthquake is different cities, stay safe everyone.\n",
      "Prediction: Disaster Tweet\n",
      "\n",
      "Sentence: weather is very good to play cricket\n",
      "Prediction: Normal Tweet\n",
      "\n",
      "Sentence: @RosieGray Now in all sincerety do you think the UN would move to Israel if there was a fraction of a chance of being annihilated?\n",
      "Prediction: Normal Tweet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "  \"An intense hurricane has made landfall, causing widespread flooding and destruction in coastal areas. Stay safe and evacuate if you can!\",\n",
    "    \"Heard about #earthquake is different cities, stay safe everyone.\",\"weather is very good to play cricket\",\n",
    "    \"@RosieGray Now in all sincerety do you think the UN would move to Israel if there was a fraction of a chance of being annihilated?\"\n",
    "  ]\n",
    "result = predict_disaster(sentences,clf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/rf_tweet.pkl']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(clf, 'model/rf_tweet.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib version: 1.3.2\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "print(\"joblib version:\", joblib.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn version: 1.4.1.post1\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(\"scikit-learn version:\", sklearn.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement joblib==1.4.1 (from versions: 0.3.2d.dev, 0.3.2e.dev, 0.3.2f.dev, 0.3.2g.dev, 0.7.0d, 0.1a0.dev0, 0.2a0.dev0, 0.3a0.dev0, 0.3.1a0.dev0, 0.3.2.dev0, 0.3.2a0.dev0, 0.3.2b0.dev0, 0.3.2rc0.dev0, 0.3.3a0.dev0, 0.3.3b0.dev0, 0.3.3rc0.dev0, 0.3.4.dev0, 0.3.5.dev0, 0.3.6.dev0, 0.3.7.dev0, 0.4.0.dev0, 0.4.1.dev0, 0.4.2.dev0, 0.4.3.dev0, 0.4.4.dev0, 0.4.5.dev0, 0.4.6.dev0, 0.5.0.dev0, 0.5.0a0.dev0, 0.5.1.dev0, 0.5.2.dev0, 0.5.3.dev0, 0.5.4.dev0, 0.5.5.dev0, 0.5.6.dev0, 0.5.7.dev0, 0.5.7a0.dev0, 0.5.7b0.dev0, 0.5.7, 0.6.0a0, 0.6.0b0, 0.6.0b2, 0.6.0b3, 0.6.0, 0.6.1, 0.6.2, 0.6.3, 0.6.4, 0.6.5, 0.7.0a0, 0.7.0b0, 0.7.0rc0, 0.7.1, 0.8.0a0, 0.8.0a2, 0.8.0a3, 0.8.0, 0.8.1, 0.8.2, 0.8.3, 0.8.3.post1, 0.8.4, 0.9.0b2, 0.9.0b3, 0.9.0b4, 0.9.1, 0.9.2, 0.9.3, 0.9.4, 0.10.0, 0.10.2, 0.10.3, 0.11a3, 0.11, 0.12.0, 0.12.1, 0.12.2, 0.12.3, 0.12.4, 0.12.5, 0.13.0, 0.13.1, 0.13.2, 0.14.0, 0.14.1, 0.15.0, 0.15.1, 0.16.0, 0.17.0, 1.0.0, 1.0.1, 1.1.0a0, 1.1.0, 1.1.1, 1.2.0, 1.3.0, 1.3.1, 1.3.2, 1.4.0)\n",
      "ERROR: No matching distribution found for joblib==1.4.1\n"
     ]
    }
   ],
   "source": [
    "! pip install joblib==1.4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install scikit-learn==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_tweet.pkld successfully from ..\\model\n",
      "Model parameters: {'memory': None, 'steps': [('tfidf', TfidfVectorizer(stop_words=['from', \"we've\", \"i'm\", 'those', 'all', 'com',\n",
      "                            \"you'd\", 'only', 'when', 'it', 'his', \"i'll\",\n",
      "                            'yours', 'further', \"we'll\", \"there's\", 'against',\n",
      "                            \"won't\", 'what', 'else', 'its', 'other', 'during',\n",
      "                            'yourself', 'has', 'otherwise', 'that', \"shouldn't\",\n",
      "                            'here', 'if', ...])), ('clf', RandomForestClassifier(n_jobs=-1))], 'verbose': False, 'tfidf': TfidfVectorizer(stop_words=['from', \"we've\", \"i'm\", 'those', 'all', 'com',\n",
      "                            \"you'd\", 'only', 'when', 'it', 'his', \"i'll\",\n",
      "                            'yours', 'further', \"we'll\", \"there's\", 'against',\n",
      "                            \"won't\", 'what', 'else', 'its', 'other', 'during',\n",
      "                            'yourself', 'has', 'otherwise', 'that', \"shouldn't\",\n",
      "                            'here', 'if', ...]), 'clf': RandomForestClassifier(n_jobs=-1), 'tfidf__analyzer': 'word', 'tfidf__binary': False, 'tfidf__decode_error': 'strict', 'tfidf__dtype': <class 'numpy.float64'>, 'tfidf__encoding': 'utf-8', 'tfidf__input': 'content', 'tfidf__lowercase': True, 'tfidf__max_df': 1.0, 'tfidf__max_features': None, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2', 'tfidf__preprocessor': None, 'tfidf__smooth_idf': True, 'tfidf__stop_words': ['from', \"we've\", \"i'm\", 'those', 'all', 'com', \"you'd\", 'only', 'when', 'it', 'his', \"i'll\", 'yours', 'further', \"we'll\", \"there's\", 'against', \"won't\", 'what', 'else', 'its', 'other', 'during', 'yourself', 'has', 'otherwise', 'that', \"shouldn't\", 'here', 'if', 'them', 'therefore', 'should', 'themselves', \"how's\", 'then', 'we', 'shall', 'any', 'nor', \"couldn't\", 'both', \"mustn't\", 'there', \"when's\", 'ever', 'he', 'again', \"you're\", 'same', \"they've\", 'to', \"can't\", 'very', \"who's\", 'hers', \"that's\", 'www', 'her', 'which', 'no', 'being', 'the', \"you'll\", \"didn't\", 'before', 'once', \"i've\", 'yourselves', 'she', 'himself', 'who', 'just', 'be', \"hadn't\", 'http', 'until', 'and', \"doesn't\", 'i', 'itself', 'is', 'out', \"aren't\", 'a', 'they', 'could', 'few', 'where', \"they'll\", 'my', \"he'll\", 'been', \"don't\", \"wasn't\", 'not', 'above', \"we're\", 'how', 'below', \"i'd\", 'ourselves', 'over', \"let's\", 'also', \"why's\", 'your', 'does', 'such', 'having', 'do', 'for', \"isn't\", \"hasn't\", 'me', 'ought', \"shan't\", 'have', 'were', 'herself', 'ours', 'while', 'hence', 'did', 'since', 'was', 'of', 'under', 'get', 'you', \"he's\", 'had', 'in', 'about', 'through', 'on', 'at', 'down', 'would', 'an', 'most', 'into', 'k', 'theirs', 'as', 'too', \"it's\", 'own', 'because', \"they'd\", 'than', 'like', \"what's\", \"where's\", 'but', \"he'd\", 'after', 'up', 'more', \"you've\", 'with', \"here's\", 'these', 'am', 'are', \"we'd\", \"she'd\", 'r', 'their', 'whom', \"wouldn't\", 'between', 'him', 'myself', \"haven't\", 'by', 'however', \"they're\", \"she's\", 'our', 'or', 'so', \"weren't\", \"she'll\", 'each', 'why', 'some', 'doing', 'off', 'can', 'cannot', 'this'], 'tfidf__strip_accents': None, 'tfidf__sublinear_tf': False, 'tfidf__token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b', 'tfidf__tokenizer': None, 'tfidf__use_idf': True, 'tfidf__vocabulary': None, 'clf__bootstrap': True, 'clf__ccp_alpha': 0.0, 'clf__class_weight': None, 'clf__criterion': 'gini', 'clf__max_depth': None, 'clf__max_features': 'sqrt', 'clf__max_leaf_nodes': None, 'clf__max_samples': None, 'clf__min_impurity_decrease': 0.0, 'clf__min_samples_leaf': 1, 'clf__min_samples_split': 2, 'clf__min_weight_fraction_leaf': 0.0, 'clf__monotonic_cst': None, 'clf__n_estimators': 100, 'clf__n_jobs': -1, 'clf__oob_score': False, 'clf__random_state': None, 'clf__verbose': 0, 'clf__warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "\n",
    "\n",
    "# Load the model using joblib\n",
    "try:\n",
    "    model = joblib.load(r\"model\\rf_tweet.pkl\")\n",
    "    print(f\"Model loaded successfully from {file_path}\")\n",
    "    # Explore the model's attributes and parameters\n",
    "    print(\"Model parameters:\", model.get_params())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
